"""OpenAI ìŒì„± ì‹¤ì‹œê°„ ì„¸ì…˜ê³¼ ìƒí˜¸ì‘ìš©í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤."""

from __future__ import annotations

import asyncio
import base64
import json
from dataclasses import dataclass, field
from typing import Dict, List, Optional, TYPE_CHECKING

import httpx
import websockets
from websockets.client import WebSocketClientProtocol

from app.config.settings import Settings
from app.services.conversation_state import ConversationStateManager
from app.utils.logging import get_logger


if TYPE_CHECKING:  # pragma: no cover - íƒ€ì… íŒíŠ¸ ì „ìš©
    from app.services.twilio_stream_handler import TwilioStreamHandler


logger = get_logger(__name__)

MIN_COMMIT_SAMPLES = 2400  # ì•½ 150ms ë¶„ëŸ‰ì˜ ì˜¤ë””ì˜¤ í™•ë³´ í›„ ì»¤ë°‹ (OpenAI ìµœì†Œ 100msë³´ë‹¤ ì—¬ìœ ìˆê²Œ)
COMMIT_DEBOUNCE_INTERVAL = 0.15  # seconds, to wait for additional audio before committing


@dataclass
class RealtimeSession:
    """OpenAI ì‹¤ì‹œê°„ ì„¸ì…˜ ìƒíƒœë¥¼ ë³´ê´€í•©ë‹ˆë‹¤."""

    websocket: WebSocketClientProtocol
    is_waiting_response: bool = False
    transcript_buffer: str = ""
    audio_buffer: List[str] = field(default_factory=list)  # base64 ì˜¤ë””ì˜¤ ì²­í¬ë“¤ì„ ë¡œì»¬ì— ë²„í¼ë§
    pending_samples: int = 0
    last_commit_request: float = 0.0
    commit_task: Optional[asyncio.Task] = None
    session_updated: bool = False  # session.updated ACK ìˆ˜ì‹  ì—¬ë¶€


class OpenAIVoiceClient:
    """OpenAI Realtime ìŒì„± APIë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”í˜• ì˜¤ë””ì˜¤ ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤."""

    def __init__(self, settings: Settings, conversation_state_manager: ConversationStateManager) -> None:
        self._settings = settings
        self._conversation_state_manager = conversation_state_manager
        self._http_client = httpx.AsyncClient(timeout=httpx.Timeout(30.0))
        self._sessions: Dict[str, RealtimeSession] = {}
        self._twilio_handler: Optional[TwilioStreamHandler] = None

    def register_twilio_handler(self, handler: "TwilioStreamHandler") -> None:
        """Twilio ìŠ¤íŠ¸ë¦¼ í•¸ë“¤ëŸ¬ë¥¼ ë“±ë¡í•˜ì—¬ ì˜¤ë””ì˜¤ ì‘ë‹µì„ ì „ë‹¬í•©ë‹ˆë‹¤."""

        self._twilio_handler = handler

    async def _flush_audio_buffer(self, stream_sid: str, session: RealtimeSession) -> None:
        """ë¡œì»¬ ë²„í¼ì˜ ì˜¤ë””ì˜¤ë¥¼ OpenAIë¡œ ì „ì†¡í•˜ê³  ì»¤ë°‹í•©ë‹ˆë‹¤."""

        if session.pending_samples < MIN_COMMIT_SAMPLES:
            logger.debug(
                "ë²„í¼ í”ŒëŸ¬ì‹œ ìŠ¤í‚µ - ìƒ˜í”Œ ë¶€ì¡±",
                extra={"stream_sid": stream_sid, "pending_samples": session.pending_samples},
            )
            return

        if not session.audio_buffer:
            logger.warning("ì˜¤ë””ì˜¤ ë²„í¼ê°€ ë¹„ì–´ìˆìŒ", extra={"stream_sid": stream_sid})
            return

        logger.debug(
            "ì˜¤ë””ì˜¤ ë²„í¼ í”ŒëŸ¬ì‹œ ì‹œì‘",
            extra={
                "stream_sid": stream_sid,
                "chunks": len(session.audio_buffer),
                "samples": session.pending_samples,
            },
        )

        # ë²„í¼ë§ëœ ëª¨ë“  ì²­í¬ë¥¼ í•œ ë²ˆì— ì „ì†¡
        total_audio_bytes = 0
        chunk_count = len(session.audio_buffer)
        
        logger.debug(
            f"ğŸ”Š ì˜¤ë””ì˜¤ ì „ì†¡ ì‹œì‘: {chunk_count}ê°œ ì²­í¬",
            extra={"stream_sid": stream_sid},
        )
        
        for idx, audio_chunk in enumerate(session.audio_buffer):
            audio_bytes = base64.b64decode(audio_chunk)
            total_audio_bytes += len(audio_bytes)
            append_message = {
                "type": "input_audio_buffer.append",
                "audio": audio_chunk,
            }
            await session.websocket.send(json.dumps(append_message))
            
            if idx == 0 or idx == chunk_count - 1:
                logger.debug(
                    f"  â†’ ì²­í¬ #{idx+1}/{chunk_count} ì „ì†¡: {len(audio_bytes)} bytes",
                    extra={"stream_sid": stream_sid},
                )

        duration_ms = (total_audio_bytes // 2) / 16  # 16kHz PCM16
        logger.info(
            f"âœ… ì˜¤ë””ì˜¤ ì²­í¬ ì „ì†¡ ì™„ë£Œ: chunks={chunk_count}, bytes={total_audio_bytes}, samples={total_audio_bytes // 2}, duration={duration_ms:.1f}ms",
            extra={"stream_sid": stream_sid},
        )

        # ë²„í¼ ì´ˆê¸°í™”
        session.audio_buffer.clear()
        session.pending_samples = 0
        
        # VAD í™œì„±í™” ì‹œì—ëŠ” ìˆ˜ë™ ì»¤ë°‹ ë¶ˆí•„ìš”
        # OpenAIê°€ ìë™ìœ¼ë¡œ ìŒì„±ì„ ê°ì§€í•˜ê³  ì²˜ë¦¬í•¨
        logger.debug(
            "âœ… ì˜¤ë””ì˜¤ ì „ì†¡ ì™„ë£Œ (VADê°€ ìë™ìœ¼ë¡œ ìŒì„± ê°ì§€ ë° ì‘ë‹µ ì²˜ë¦¬)",
            extra={"stream_sid": stream_sid},
        )

    async def _debounced_flush(self, stream_sid: str, session: RealtimeSession) -> None:
        """ì§§ì€ ì§€ì—° í›„ ë²„í¼ë¥¼ í”ŒëŸ¬ì‹œí•˜ì—¬ ì¶©ë¶„í•œ ì˜¤ë””ì˜¤ê°€ ëˆ„ì ë˜ë„ë¡ í•©ë‹ˆë‹¤."""

        try:
            await asyncio.sleep(COMMIT_DEBOUNCE_INTERVAL)
            await self._flush_audio_buffer(stream_sid=stream_sid, session=session)
        except asyncio.CancelledError:
            logger.debug("ë²„í¼ í”ŒëŸ¬ì‹œ ì˜ˆì•½ ì·¨ì†Œë¨", extra={"stream_sid": stream_sid})
            raise
        finally:
            session.commit_task = None

    async def create_session(self, stream_sid: str, audio_format: str) -> None:
        """Twilio ìŠ¤íŠ¸ë¦¼ê³¼ ì—°ë™í•  OpenAI ì‹¤ì‹œê°„ ì„¸ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤."""

        print(f"\n\nğŸš€ğŸš€ğŸš€ create_session í˜¸ì¶œë¨! stream_sid={stream_sid}, audio_format={audio_format}\n\n")
        
        logger.info("OpenAI ì„¸ì…˜ ìƒì„± ì‹œì‘", extra={"stream_sid": stream_sid})
        system_prompt = self._conversation_state_manager.build_system_prompt(stream_sid=stream_sid)

        try:
            # GA ë²„ì „: ì§ì ‘ WebSocket ì—°ê²° (ì„¸ì…˜ ìƒì„± API ë¶ˆí•„ìš”)
            websocket = await self._connect_websocket_direct()
            self._sessions[stream_sid] = RealtimeSession(websocket=websocket)
            
            # ë¨¼ì € ìˆ˜ì‹  íƒœìŠ¤í¬ ì‹œì‘ (session.created ì´ë²¤íŠ¸ ìˆ˜ì‹ ìš©)
            asyncio.create_task(self._receive_and_forward(stream_sid=stream_sid))
            
            # session.created ì´ë²¤íŠ¸ë¥¼ ê¸°ë‹¤ë¦¼
            await asyncio.sleep(0.1)
            
            # ì„¸ì…˜ ì„¤ì • ì—…ë°ì´íŠ¸ - system prompt ë° ì˜¤ë””ì˜¤ í¬ë§· ì„¤ì •
            await self._configure_session(
                stream_sid=stream_sid,
                session=self._sessions[stream_sid],
                system_prompt=system_prompt,
            )
            
            logger.info("OpenAI ì„¸ì…˜ ì¤€ë¹„ ì™„ë£Œ - VAD ìë™ ì‘ë‹µ ëª¨ë“œ", extra={"stream_sid": stream_sid})
        except Exception:  # pylint: disable=broad-except
            logger.exception("OpenAI ì„¸ì…˜ ìƒì„± ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜", extra={"stream_sid": stream_sid})
            raise

    async def send_audio_chunk(self, stream_sid: str, audio_chunk_b64: str) -> None:
        """Twilioì—ì„œ ìˆ˜ì‹ í•œ base64 ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë¡œì»¬ ë²„í¼ì— ì €ì¥í•©ë‹ˆë‹¤."""

        session = self._sessions.get(stream_sid)
        if not session:
            logger.warning("ì„¸ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ ì˜¤ë””ì˜¤ ì „ì†¡ ë¶ˆê°€", extra={"stream_sid": stream_sid})
            return

        try:
            audio_bytes = base64.b64decode(audio_chunk_b64)
        except (ValueError, TypeError) as error:
            logger.warning("OpenAIë¡œ ì „ì†¡í•  ì˜¤ë””ì˜¤ base64 ë””ì½”ë”© ì‹¤íŒ¨", extra={"stream_sid": stream_sid, "error": str(error)})
            return

        # ë¡œì»¬ ë²„í¼ì— ì¶”ê°€ (OpenAIë¡œ ì¦‰ì‹œ ì „ì†¡í•˜ì§€ ì•ŠìŒ)
        session.audio_buffer.append(audio_chunk_b64)
        session.pending_samples += len(audio_bytes) // 2  # 2 bytes per sample (PCM16 mono)

        # ì¶©ë¶„í•œ ìƒ˜í”Œì´ ëˆ„ì ë˜ë©´ í”ŒëŸ¬ì‹œ ì˜ˆì•½
        if session.pending_samples >= MIN_COMMIT_SAMPLES:
            session.last_commit_request = asyncio.get_event_loop().time()
            if session.commit_task and not session.commit_task.done():
                session.commit_task.cancel()
            session.commit_task = asyncio.create_task(
                self._debounced_flush(stream_sid=stream_sid, session=session)
            )
            logger.debug(
                "ë²„í¼ í”ŒëŸ¬ì‹œ ì˜ˆì•½",
                extra={
                    "stream_sid": stream_sid,
                    "pending_samples": session.pending_samples,
                    "buffer_chunks": len(session.audio_buffer),
                },
            )

    async def close_session(self, stream_sid: str) -> None:
        """OpenAI ì„¸ì…˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."""

        logger.info("OpenAI ì„¸ì…˜ ì¢…ë£Œ", extra={"stream_sid": stream_sid})
        session = self._sessions.pop(stream_sid, None)
        if session:
            # ì˜ˆì•½ëœ í”ŒëŸ¬ì‹œ íƒœìŠ¤í¬ ì·¨ì†Œ
            if session.commit_task and not session.commit_task.done():
                session.commit_task.cancel()
                try:
                    await session.commit_task
                except asyncio.CancelledError:
                    pass
                except Exception:  # pylint: disable=broad-except
                    logger.exception("í”ŒëŸ¬ì‹œ íƒœìŠ¤í¬ ì·¨ì†Œ ì¤‘ ì˜¤ë¥˜", extra={"stream_sid": stream_sid})
            
            # ì ì‹œ ëŒ€ê¸°í•˜ì—¬ ì§„í–‰ ì¤‘ì¸ ì‘ì—… ì™„ë£Œ
            await asyncio.sleep(0.01)
            
            # ë²„í¼ì— ì¶©ë¶„í•œ ìƒ˜í”Œì´ ë‚¨ì•„ìˆìœ¼ë©´ ë§ˆì§€ë§‰ìœ¼ë¡œ í”ŒëŸ¬ì‹œ
            if session.pending_samples >= MIN_COMMIT_SAMPLES and session.audio_buffer:
                try:
                    logger.debug(
                        "ì¢…ë£Œ ì‹œ ì”ì—¬ ë²„í¼ í”ŒëŸ¬ì‹œ",
                        extra={
                            "stream_sid": stream_sid,
                            "pending_samples": session.pending_samples,
                            "buffer_chunks": len(session.audio_buffer),
                        },
                    )
                    await self._flush_audio_buffer(stream_sid=stream_sid, session=session)
                except Exception:  # pylint: disable=broad-except
                    logger.warning("ì¢…ë£Œ ì‹œ ë²„í¼ í”ŒëŸ¬ì‹œ ì¤‘ ì˜¤ë¥˜", extra={"stream_sid": stream_sid})
            else:
                logger.debug(
                    "ì¢…ë£Œ ì‹œ ë²„í¼ í”ŒëŸ¬ì‹œ ìŠ¤í‚µ - ìƒ˜í”Œ ë¶€ì¡±",
                    extra={
                        "stream_sid": stream_sid,
                        "pending_samples": session.pending_samples,
                        "buffer_chunks": len(session.audio_buffer),
                    },
                )
            
            # ë²„í¼ ì •ë¦¬
            session.audio_buffer.clear()
            session.pending_samples = 0
            await session.websocket.close()

    async def _configure_session(self, stream_sid: str, session: RealtimeSession, system_prompt: str) -> None:
        """WebSocket ì—°ê²° í›„ ì„¸ì…˜ì„ êµ¬ì„±í•©ë‹ˆë‹¤ (system prompt, ì˜¤ë””ì˜¤ í¬ë§· ë“±)."""
        
        logger.info(
            f"ğŸ” ì „ì†¡í•  System Prompt: {system_prompt[:100]}...",
            extra={"stream_sid": stream_sid},
        )
        
        # 1ë‹¨ê³„: session.update ì „ì†¡
        update_message = {
            "type": "session.update",
            "session": {
                "modalities": ["text", "audio"],
                "instructions": system_prompt,
                "voice": "alloy",
                "input_audio_format": "pcm16",
                "output_audio_format": "pcm16",
                "input_audio_transcription": {
                    "model": "whisper-1"
                },
                "turn_detection": {
                    "type": "server_vad",
                    "threshold": 0.5,
                    "prefix_padding_ms": 300,
                    "silence_duration_ms": 700  # 700ms ì¹¨ë¬µ í›„ ë§ì´ ëë‚¬ë‹¤ê³  íŒë‹¨
                },
                "temperature": 0.6,
                "max_response_output_tokens": 200,
            },
        }
        await session.websocket.send(json.dumps(update_message))
        logger.info("âœ… session.update ì „ì†¡ ì™„ë£Œ", extra={"stream_sid": stream_sid})
        
        # 2ë‹¨ê³„: session.updated ACK ëŒ€ê¸° (ìµœëŒ€ 2ì´ˆ)
        session_updated = False
        for _ in range(20):  # 0.1ì´ˆì”© 20ë²ˆ = 2ì´ˆ
            await asyncio.sleep(0.1)
            # _receive_and_forwardì—ì„œ session.updatedë¥¼ ë°›ìœ¼ë©´ í”Œë˜ê·¸ ì„¤ì •
            if hasattr(session, 'session_updated') and session.session_updated:
                session_updated = True
                break
        
        if not session_updated:
            logger.warning("âš ï¸ session.updated ACKë¥¼ ë°›ì§€ ëª»í•¨ - ì„¤ì •ì´ ì ìš©ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŒ", extra={"stream_sid": stream_sid})
        else:
            logger.info("âœ… session.updated ACK ìˆ˜ì‹  ì™„ë£Œ", extra={"stream_sid": stream_sid})
        
        # 3ë‹¨ê³„: conversation.item.createë¡œ system ë©”ì‹œì§€ ì¶”ê°€ (ì¤‘ë³µ ì•ˆì „ë§)
        system_message = {
            "type": "conversation.item.create",
            "item": {
                "type": "message",
                "role": "system",
                "content": [
                    {
                        "type": "input_text",
                        "text": "í•­ìƒ í•œêµ­ì–´(ì¡´ëŒ“ë§)ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì˜ì–´, ìŠ¤í˜ì¸ì–´, í”„ë‘ìŠ¤ì–´, ì•„ëì–´ ë“± ë‹¤ë¥¸ ì–¸ì–´ëŠ” ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€ì…ë‹ˆë‹¤."
                    }
                ]
            }
        }
        await session.websocket.send(json.dumps(system_message))
        logger.info("âœ… system ë©”ì‹œì§€ ì¶”ê°€ ì™„ë£Œ", extra={"stream_sid": stream_sid})
        
        await asyncio.sleep(0.2)  # conversation.item.created ACK ëŒ€ê¸°
        
        logger.info(
            "OpenAI ì„¸ì…˜ ì„¤ì • ì™„ë£Œ (3ë‹¨ê³„)",
            extra={"stream_sid": stream_sid, "voice": "alloy", "format": "pcm16@16kHz"},
        )

    async def _request_response(self, stream_sid: str, session: RealtimeSession) -> None:
        """OpenAIì— ìŒì„± ì‘ë‹µ ìƒì„±ì„ ìš”ì²­í•©ë‹ˆë‹¤."""

        # ì‘ë‹µ ë ˆë²¨ì—ì„œë„ í•œêµ­ì–´ ê°•ì œ (3ì¤‘ ì•ˆì „ë§)
        response_request = {
            "type": "response.create",
            "response": {
                "instructions": "ì§€ê¸ˆë¶€í„° í•œêµ­ì–´(ì¡´ëŒ“ë§)ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ ì–¸ì–´ ì‚¬ìš© ê¸ˆì§€."
            }
        }
        await session.websocket.send(json.dumps(response_request))
        session.is_waiting_response = True
        
        logger.info(
            "OpenAI ì‘ë‹µ ìƒì„± ìš”ì²­ ì „ì†¡ (í•œêµ­ì–´ ê°•ì œ)",
            extra={"stream_sid": stream_sid},
        )

    async def _connect_websocket_direct(self) -> WebSocketClientProtocol:
        """OpenAI Realtime WebSocketì— ì§ì ‘ ì—°ê²°í•©ë‹ˆë‹¤ (GA ë²„ì „)."""

        realtime_url = f"wss://api.openai.com/v1/realtime?model={self._settings.openai_realtime_model}"
        
        # API í‚¤ ë§ˆìŠ¤í‚¹ (ì²˜ìŒ 10ì, ë§ˆì§€ë§‰ 4ìë§Œ í‘œì‹œ)
        api_key = self._settings.openai_api_key
        masked_key = f"{api_key[:10]}...{api_key[-4:]}" if len(api_key) > 14 else "***"
        
        logger.info(
            f"ğŸ” DEBUG: ì‚¬ìš© ì¤‘ì¸ ì„¤ì •",
            extra={
                "model": self._settings.openai_realtime_model,
                "api_key_prefix": masked_key,
            },
        )
        
        headers = {
            "Authorization": f"Bearer {api_key}",
        }

        logger.debug(f"WebSocket ì—°ê²° ì‹œë„: {realtime_url}")
        websocket = await websockets.connect(realtime_url, additional_headers=headers, max_size=None)
        logger.info("OpenAI Realtime WebSocket ì—°ê²° ì„±ê³µ")
        return websocket

    async def _receive_and_forward(self, stream_sid: str) -> None:
        """OpenAI ì‘ë‹µì„ ìˆ˜ì‹ í•˜ê³  Twilioë¡œ ì „ë‹¬í•˜ëŠ” íë¦„ì„ ìœ ì§€í•©ë‹ˆë‹¤."""

        session = self._sessions.get(stream_sid)
        if not session:
            logger.warning("OpenAI ì„¸ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ ìˆ˜ì‹  ë£¨í”„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.", extra={"stream_sid": stream_sid})
            return

        websocket = session.websocket

        try:
            async for message in websocket:
                try:
                    payload = json.loads(message)
                except json.JSONDecodeError:
                    logger.warning("OpenAI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨", extra={"stream_sid": stream_sid})
                    continue

                event_type = payload.get("type")

                # ëª¨ë“  ì´ë²¤íŠ¸ íƒ€ì…ì„ ëª…í™•í•˜ê²Œ ë¡œê¹…
                logger.info(
                    f"ğŸ“¨ OpenAI ì´ë²¤íŠ¸: {event_type}",
                    extra={"stream_sid": stream_sid, "event_type": event_type},
                )

                if event_type == "session.created":
                    # WebSocket ì—°ê²° ì§í›„ ì²« ì´ë²¤íŠ¸
                    logger.info(
                        "âœ… OpenAI ì„¸ì…˜ ìƒì„± ì™„ë£Œ (session.created)",
                        extra={"stream_sid": stream_sid},
                    )
                elif event_type == "session.updated":
                    # ì„¸ì…˜ ì„¤ì • ì—…ë°ì´íŠ¸ í™•ì¸ - í”Œë˜ê·¸ ì„¤ì •
                    session.session_updated = True
                    session_data = payload.get("session", {})
                    logger.info(
                        f"âœ… session.updated ìˆ˜ì‹ ! voice={session_data.get('voice')}, "
                        f"modalities={session_data.get('modalities')}",
                        extra={"stream_sid": stream_sid}
                    )
                elif event_type == "input_audio_buffer.committed":
                    # ì‚¬ìš©ì ì˜¤ë””ì˜¤ ì»¤ë°‹ í™•ì¸
                    logger.info(
                        "âœ… ì‚¬ìš©ì ì˜¤ë””ì˜¤ ì»¤ë°‹ë¨ (OpenAI í™•ì¸)",
                        extra={"stream_sid": stream_sid},
                    )
                elif event_type == "conversation.item.input_audio_transcription.completed":
                    # ì‚¬ìš©ì ìŒì„± íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì™„ë£Œ
                    transcript = payload.get("transcript", "")
                    logger.error(
                        f"ğŸ¤ ì‚¬ìš©ì ë§í•¨: {transcript}",
                        extra={"stream_sid": stream_sid},
                    )
                elif event_type == "response.created":
                    # ì‘ë‹µ ìƒì„±ì´ ì‹œì‘ë˜ì—ˆìŒì„ í™•ì¸
                    logger.info(
                        "OpenAI ì‘ë‹µ ìƒì„± ì‹œì‘",
                        extra={"stream_sid": stream_sid, "response_id": payload.get("response", {}).get("id")},
                    )
                elif event_type == "response.output_audio.delta":
                    # í•µì‹¬: response.output_audio.delta!
                    audio_delta = payload.get("delta")
                    logger.error(
                        f"ğŸµ response.output_audio.delta ìˆ˜ì‹ ! delta={audio_delta[:50] if audio_delta else None}..., has_handler={bool(self._twilio_handler)}",
                        extra={"stream_sid": stream_sid},
                    )
                    if audio_delta and self._twilio_handler:
                        logger.info(
                            "âœ… OpenAI ì˜¤ë””ì˜¤ ë¸íƒ€ ìˆ˜ì‹  â†’ Twilio ì „ì†¡",
                            extra={"stream_sid": stream_sid, "payload_length": len(audio_delta)},
                        )
                        await self._twilio_handler.send_audio_to_twilio(
                            stream_sid=stream_sid,
                            audio_payload_b64=audio_delta,
                        )
                    else:
                        logger.warning(
                            "ì˜¤ë””ì˜¤ ë¸íƒ€ê°€ ë¹„ì–´ìˆê±°ë‚˜ Twilio í•¸ë“¤ëŸ¬ ì—†ìŒ",
                            extra={"stream_sid": stream_sid, "has_delta": bool(audio_delta), "has_handler": bool(self._twilio_handler)},
                        )
                elif event_type == "response.output_audio.done":
                    logger.info(
                        "OpenAI ì˜¤ë””ì˜¤ ì¶œë ¥ ì™„ë£Œ",
                        extra={"stream_sid": stream_sid},
                    )
                elif event_type == "response.output_item.added":
                    # ì¶œë ¥ ì•„ì´í…œ ì¶”ê°€ ì´ë²¤íŠ¸
                    logger.error(
                        f"ğŸ” DEBUG: response.output_item.added - {payload.get('item', {}).get('type')}",
                        extra={"stream_sid": stream_sid},
                    )
                elif event_type == "response.content_part.added":
                    # ì½˜í…ì¸  íŒŒíŠ¸ ì¶”ê°€ ì´ë²¤íŠ¸
                    logger.error(
                        f"ğŸ” DEBUG: response.content_part.added - {payload.get('part', {}).get('type')}",
                        extra={"stream_sid": stream_sid},
                    )
                elif event_type == "response.output_audio_transcript.delta":
                    # ì˜¤ë””ì˜¤ì˜ í…ìŠ¤íŠ¸ ë³€í™˜ë³¸
                    transcript_delta = payload.get("delta", "")
                    print(f"ğŸ—£ï¸ AI ë§í•˜ëŠ” ì¤‘: {transcript_delta}")
                    logger.error(
                        f"ğŸ—£ï¸ AI íŠ¸ëœìŠ¤í¬ë¦½íŠ¸: {transcript_delta}",
                        extra={"stream_sid": stream_sid, "transcript": transcript_delta},
                    )
                elif event_type == "response.output_text.delta":
                    text_delta = payload.get("delta", "")
                    session.transcript_buffer += text_delta
                elif event_type == "response.done":
                    # ì‘ë‹µ ì™„ë£Œ
                    session.is_waiting_response = False
                    response_data = payload.get("response", {})
                    
                    # ë””ë²„ê¹…: ì „ì²´ response êµ¬ì¡° ì¶œë ¥
                    output_items = response_data.get("output", [])
                    logger.error(
                        f"ğŸ” DEBUG ì‘ë‹µì™„ë£Œ: status={response_data.get('status')}, "
                        f"status_details={response_data.get('status_details')}, "
                        f"output_count={len(output_items)}, "
                        f"output_types={[item.get('type') for item in output_items] if output_items else 'none'}, "
                        f"usage={response_data.get('usage')}"
                    )
                    if session.transcript_buffer:
                        self._conversation_state_manager.update_context(
                            stream_sid=stream_sid,
                            key="last_ai_response",
                            value=session.transcript_buffer,
                        )
                        session.transcript_buffer = ""
                elif event_type == "response.completed":
                    session.is_waiting_response = False
                    if session.transcript_buffer:
                        self._conversation_state_manager.update_context(
                            stream_sid=stream_sid,
                            key="last_ai_response",
                            value=session.transcript_buffer,
                        )
                        session.transcript_buffer = ""
                elif event_type == "response.error":
                    logger.error(
                        "OpenAI ì‘ë‹µ ì˜¤ë¥˜: %s",
                        payload.get("error"),
                        extra={"stream_sid": stream_sid},
                    )
                    session.is_waiting_response = False
                elif event_type == "error":
                    logger.error(
                        "OpenAI ì¼ë°˜ ì˜¤ë¥˜ ì´ë²¤íŠ¸: %s",
                        payload,
                        extra={"stream_sid": stream_sid},
                    )
                    session.is_waiting_response = False

        except websockets.ConnectionClosed:
            logger.info("OpenAI WebSocket ì—°ê²° ì¢…ë£Œ", extra={"stream_sid": stream_sid})
        except Exception:  # pylint: disable=broad-except
            logger.exception("OpenAI ì‘ë‹µ ìˆ˜ì‹  ì¤‘ ì˜¤ë¥˜", extra={"stream_sid": stream_sid})



